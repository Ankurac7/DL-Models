{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='coarse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "X_train = np.array([cv2.resize(img, (140, 140)) for img in X_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([cv2.resize(img, (140, 140)) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 20)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "y_train=enc.fit_transform(y_train).toarray().astype(int)\n",
    "y_test=enc.transform(y_test).toarray().astype(int)\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmenter():\n",
    "    '''\n",
    "    Create a Sequential model composed of 2 layers\n",
    "    Returns:\n",
    "        tf.keras.Sequential\n",
    "    '''\n",
    "    data_augmentation = tf.keras.Sequential()\n",
    "    data_augmentation.add(tfl.RandomFlip('horizontal'))\n",
    "    data_augmentation.add(tfl.RandomRotation(0.2))\n",
    "\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = data_augmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch(input_shape, data_augmentation):\n",
    "\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    layer = data_augmenter()(input_img)\n",
    "    layer=tfl.Conv2D(filters= 96 , kernel_size= 11,strides=(4, 4))(layer)\n",
    "    layer=tfl.ReLU()(layer)\n",
    "    layer=tfl.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(layer)\n",
    "    layer=tfl.BatchNormalization()(layer,training=True)\n",
    "    \n",
    "    layer=tfl.Conv2D(filters= 256 , kernel_size= 5 ,strides=(1, 1), padding='same')(layer)\n",
    "    layer=tfl.ReLU()(layer)\n",
    "    layer=tfl.MaxPool2D(pool_size=(3, 3), strides=(2,2), padding='same')(layer)\n",
    "    layer=tfl.BatchNormalization()(layer,training=True)\n",
    "\n",
    "    layer=tfl.Conv2D(filters= 384 , kernel_size= 3 ,strides=(1, 1), padding='same')(layer)\n",
    "    layer=tfl.ReLU()(layer)\n",
    "    layer=tfl.Conv2D(filters= 384 , kernel_size= 3 ,strides=(1, 1), padding='same')(layer)\n",
    "    layer=tfl.ReLU()(layer)\n",
    "    layer=tfl.Conv2D(filters= 256 , kernel_size= 3 ,strides=(1, 1), padding='same')(layer)\n",
    "    layer=tfl.ReLU()(layer)\n",
    "    layer=tfl.MaxPool2D(pool_size=(3, 3), strides=(2,2), padding='same')(layer)\n",
    "    layer=tfl.BatchNormalization()(layer,training=True)\n",
    "\n",
    "    layer=tfl.Flatten()(layer)\n",
    "    \n",
    "    layer=tfl.Dense(units=4096, activation='relu')(layer)\n",
    "    layer=tfl.Dropout(0.2)(layer)\n",
    "    layer=tfl.BatchNormalization()(layer,training=True)\n",
    "\n",
    "    layer=tfl.Dense(units=4096, activation='relu')(layer)\n",
    "    layer=tfl.Dropout(0.2)(layer)\n",
    "    layer=tfl.BatchNormalization()(layer,training=True)\n",
    "\n",
    "    layer=tfl.Dense(units=1000, activation='relu')(layer)\n",
    "    layer=tfl.Dropout(0.2)(layer)\n",
    "    layer=tfl.BatchNormalization()(layer,training=True)\n",
    "\n",
    "    outputs=tfl.Dense(units= 20 , activation='softmax')(layer)\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 140, 140, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 140, 140, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 33, 33, 96)        34944     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 33, 33, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 17, 17, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 17, 17, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 256)       614656    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 17, 17, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 9, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 9, 9, 384)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 384)         1327488   \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 9, 9, 384)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 256)         884992    \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 9, 9, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 5, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1000)             4000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                20020     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,903,228\n",
      "Trainable params: 50,883,628\n",
      "Non-trainable params: 19,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = arch((140, 140, 3),data_augmentation)\n",
    "conv_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8192)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(8192)\n",
    "history = conv_model.fit(train_dataset,epochs=10,validation_data=test_dataset,batch_size=8192,shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
